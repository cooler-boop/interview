/**
 * ä¼ä¸šçº§ç®€å†è§£ææœåŠ¡
 * æ”¯æŒPDFã€DOCã€DOCXã€TXTæ ¼å¼
 * é›†æˆNLPå¤„ç†å’Œä¸­æ–‡ä¼˜åŒ–
 */

import express from 'express'
import multer from 'multer'
import cors from 'cors'
import helmet from 'helmet'
import rateLimit from 'express-rate-limit'
import { body, validationResult } from 'express-validator'
import fs from 'fs/promises'
import path from 'path'
import { fileURLToPath } from 'url'
import ResumeParser from 'resume-parser'
import pdfParse from 'pdf-parse'
import mammoth from 'mammoth'
import { NlpManager } from 'node-nlp'

const __filename = fileURLToPath(import.meta.url)
const __dirname = path.dirname(__filename)

const app = express()
const PORT = process.env.PORT || 3001

// å®‰å…¨ä¸­é—´ä»¶
app.use(helmet())
app.use(cors({
  origin: process.env.FRONTEND_URL || 'http://localhost:3000',
  credentials: true
}))

// é€Ÿç‡é™åˆ¶
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15åˆ†é’Ÿ
  max: 100, // é™åˆ¶æ¯ä¸ªIP 100æ¬¡è¯·æ±‚
  message: {
    error: 'è¯·æ±‚è¿‡äºé¢‘ç¹ï¼Œè¯·ç¨åå†è¯•'
  }
})
app.use('/api/', limiter)

// æ–‡ä»¶ä¸Šä¼ é…ç½®
const storage = multer.diskStorage({
  destination: async (req, file, cb) => {
    const uploadDir = path.join(__dirname, 'uploads')
    try {
      await fs.mkdir(uploadDir, { recursive: true })
      cb(null, uploadDir)
    } catch (error) {
      cb(error)
    }
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9)
    cb(null, file.fieldname + '-' + uniqueSuffix + path.extname(file.originalname))
  }
})

const upload = multer({
  storage,
  limits: {
    fileSize: 10 * 1024 * 1024, // 10MBé™åˆ¶
  },
  fileFilter: (req, file, cb) => {
    const allowedTypes = [
      'application/pdf',
      'application/msword',
      'application/vnd.openxmlformats-officedocument.wordprocessingml.document',
      'text/plain'
    ]
    
    if (allowedTypes.includes(file.mimetype)) {
      cb(null, true)
    } else {
      cb(new Error('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼'), false)
    }
  }
})

// NLPç®¡ç†å™¨åˆå§‹åŒ–
const nlpManager = new NlpManager({ languages: ['zh', 'en'] })

// è®­ç»ƒä¸­æ–‡ç®€å†å…³é”®è¯è¯†åˆ«
async function initializeNLP() {
  // æ•™è‚²èƒŒæ™¯ç›¸å…³
  nlpManager.addNamedEntityText('education', 'education_degree', ['zh'], ['å­¦å£«', 'ç¡•å£«', 'åšå£«', 'æœ¬ç§‘', 'ç ”ç©¶ç”Ÿ', 'ä¸“ç§‘', 'å¤§ä¸“'])
  nlpManager.addNamedEntityText('education', 'education_school', ['zh'], ['å¤§å­¦', 'å­¦é™¢', 'å­¦æ ¡', 'é™¢æ ¡'])
  
  // å·¥ä½œç»éªŒç›¸å…³
  nlpManager.addNamedEntityText('experience', 'job_title', ['zh'], ['å·¥ç¨‹å¸ˆ', 'ç»ç†', 'ä¸»ç®¡', 'æ€»ç›‘', 'ä¸“å‘˜', 'åŠ©ç†', 'å®ä¹ ç”Ÿ'])
  nlpManager.addNamedEntityText('experience', 'company_type', ['zh'], ['æœ‰é™å…¬å¸', 'è‚¡ä»½å…¬å¸', 'ç§‘æŠ€å…¬å¸', 'é›†å›¢'])
  
  // æŠ€èƒ½ç›¸å…³
  nlpManager.addNamedEntityText('skills', 'tech_skills', ['zh'], ['JavaScript', 'Python', 'Java', 'React', 'Vue', 'Node.js'])
  
  await nlpManager.train()
  console.log('NLPæ¨¡å‹è®­ç»ƒå®Œæˆ')
}

// ä¼ä¸šçº§ç®€å†è§£æå™¨
class EnterpriseResumeParser {
  constructor() {
    this.chineseKeywords = {
      personal: ['å§“å', 'æ€§åˆ«', 'å¹´é¾„', 'å‡ºç”Ÿ', 'ç”µè¯', 'é‚®ç®±', 'åœ°å€', 'è”ç³»æ–¹å¼'],
      education: ['æ•™è‚²èƒŒæ™¯', 'æ•™è‚²ç»å†', 'å­¦å†', 'æ¯•ä¸šé™¢æ ¡', 'ä¸“ä¸š', 'å­¦ä½', 'æ¯•ä¸šæ—¶é—´'],
      experience: ['å·¥ä½œç»å†', 'å·¥ä½œç»éªŒ', 'å®ä¹ ç»å†', 'é¡¹ç›®ç»éªŒ', 'èŒä¸šç»å†', 'ä»»èŒ'],
      skills: ['æŠ€èƒ½', 'æŠ€æœ¯æ ˆ', 'ä¸“ä¸šæŠ€èƒ½', 'æŒæ¡æŠ€æœ¯', 'ç†Ÿæ‚‰', 'ç²¾é€š', 'äº†è§£'],
      projects: ['é¡¹ç›®ç»éªŒ', 'é¡¹ç›®ç»å†', 'å‚ä¸é¡¹ç›®', 'è´Ÿè´£é¡¹ç›®', 'ä¸»è¦é¡¹ç›®'],
      certifications: ['è¯ä¹¦', 'è®¤è¯', 'èµ„æ ¼è¯', 'è·å¥–', 'è£èª‰'],
      languages: ['è¯­è¨€èƒ½åŠ›', 'å¤–è¯­æ°´å¹³', 'è¯­è¨€æŠ€èƒ½']
    }
  }

  /**
   * è§£æç®€å†æ–‡ä»¶
   */
  async parseResume(filePath, originalName, targetPosition = '') {
    try {
      const ext = path.extname(originalName).toLowerCase()
      let text = ''
      
      // æ ¹æ®æ–‡ä»¶ç±»å‹æå–æ–‡æœ¬
      switch (ext) {
        case '.pdf':
          text = await this.extractPDFText(filePath)
          break
        case '.docx':
          text = await this.extractDocxText(filePath)
          break
        case '.doc':
          text = await this.extractDocText(filePath)
          break
        case '.txt':
          text = await this.extractTxtText(filePath)
          break
        default:
          throw new Error('ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼')
      }

      // ä½¿ç”¨resume-parserè¿›è¡ŒåŸºç¡€è§£æ
      const basicParsed = await this.parseWithResumeParser(filePath)
      
      // ä½¿ç”¨è‡ªå®šä¹‰NLPè¿›è¡Œä¸­æ–‡ä¼˜åŒ–è§£æ
      const enhancedParsed = await this.enhanceWithNLP(text, basicParsed)
      
      // è®¡ç®—ä¸ç›®æ ‡èŒä½çš„åŒ¹é…åº¦
      const matchAnalysis = await this.calculateJobMatch(enhancedParsed, targetPosition)
      
      // ç”Ÿæˆæ”¹è¿›å»ºè®®
      const improvements = this.generateImprovements(enhancedParsed, targetPosition)
      
      return {
        success: true,
        data: {
          ...enhancedParsed,
          matchAnalysis,
          improvements,
          originalFileName: originalName,
          parsedAt: new Date().toISOString()
        }
      }
      
    } catch (error) {
      console.error('ç®€å†è§£æå¤±è´¥:', error)
      throw error
    } finally {
      // æ¸…ç†ä¸´æ—¶æ–‡ä»¶
      try {
        await fs.unlink(filePath)
      } catch (cleanupError) {
        console.warn('æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥:', cleanupError)
      }
    }
  }

  /**
   * PDFæ–‡æœ¬æå–
   */
  async extractPDFText(filePath) {
    const dataBuffer = await fs.readFile(filePath)
    const data = await pdfParse(dataBuffer)
    return data.text
  }

  /**
   * DOCXæ–‡æœ¬æå–
   */
  async extractDocxText(filePath) {
    const result = await mammoth.extractRawText({ path: filePath })
    return result.value
  }

  /**
   * DOCæ–‡æœ¬æå–ï¼ˆéœ€è¦å®‰è£…catdocï¼‰
   */
  async extractDocText(filePath) {
    // é™çº§åˆ°resume-parserå¤„ç†
    return ''
  }

  /**
   * TXTæ–‡æœ¬æå–
   */
  async extractTxtText(filePath) {
    return await fs.readFile(filePath, 'utf-8')
  }

  /**
   * ä½¿ç”¨resume-parserè¿›è¡ŒåŸºç¡€è§£æ
   */
  async parseWithResumeParser(filePath) {
    return new Promise((resolve, reject) => {
      ResumeParser.parseResumeFile(filePath, (data, err) => {
        if (err) {
          reject(err)
        } else {
          resolve(data)
        }
      })
    })
  }

  /**
   * ä½¿ç”¨NLPå¢å¼ºè§£æç»“æœ
   */
  async enhanceWithNLP(text, basicParsed) {
    const nlpResult = await nlpManager.process('zh', text)
    
    // æå–ä¸ªäººä¿¡æ¯
    const personalInfo = this.extractPersonalInfo(text)
    
    // æå–æ•™è‚²èƒŒæ™¯
    const education = this.extractEducation(text, basicParsed.education)
    
    // æå–å·¥ä½œç»éªŒ
    const experience = this.extractExperience(text, basicParsed.experience)
    
    // æå–æŠ€èƒ½
    const skills = this.extractSkills(text, basicParsed.skills)
    
    // æå–é¡¹ç›®ç»éªŒ
    const projects = this.extractProjects(text)
    
    return {
      personalInfo: {
        ...basicParsed.personalInfo,
        ...personalInfo
      },
      education,
      experience,
      skills,
      projects,
      rawText: text,
      nlpEntities: nlpResult.entities
    }
  }

  /**
   * æå–ä¸ªäººä¿¡æ¯
   */
  extractPersonalInfo(text) {
    const info = {}
    
    // æå–é‚®ç®±
    const emailRegex = /[\w\.-]+@[\w\.-]+\.\w+/g
    const emails = text.match(emailRegex)
    if (emails) info.email = emails[0]
    
    // æå–ç”µè¯
    const phoneRegex = /1[3-9]\d{9}|(\d{3,4}[-\s]?)?\d{7,8}/g
    const phones = text.match(phoneRegex)
    if (phones) info.phone = phones[0]
    
    // æå–å§“åï¼ˆç®€å•è§„åˆ™ï¼‰
    const nameRegex = /å§“\s*å[:ï¼š]\s*([^\n\r]{2,4})/
    const nameMatch = text.match(nameRegex)
    if (nameMatch) info.name = nameMatch[1].trim()
    
    return info
  }

  /**
   * æå–æ•™è‚²èƒŒæ™¯
   */
  extractEducation(text, basicEducation = []) {
    const educationSection = this.extractSection(text, this.chineseKeywords.education)
    
    // æå–å­¦ä½ä¿¡æ¯
    const degreeRegex = /(å­¦å£«|ç¡•å£«|åšå£«|æœ¬ç§‘|ç ”ç©¶ç”Ÿ|ä¸“ç§‘|å¤§ä¸“)/g
    const degrees = educationSection.match(degreeRegex) || []
    
    // æå–å­¦æ ¡ä¿¡æ¯
    const schoolRegex = /([^\n\r]*(?:å¤§å­¦|å­¦é™¢|å­¦æ ¡)[^\n\r]*)/g
    const schools = educationSection.match(schoolRegex) || []
    
    // æå–ä¸“ä¸šä¿¡æ¯
    const majorRegex = /ä¸“ä¸š[:ï¼š]\s*([^\n\r]+)/g
    const majors = educationSection.match(majorRegex) || []
    
    return {
      degrees,
      schools,
      majors,
      raw: educationSection,
      basic: basicEducation
    }
  }

  /**
   * æå–å·¥ä½œç»éªŒ
   */
  extractExperience(text, basicExperience = []) {
    const experienceSection = this.extractSection(text, this.chineseKeywords.experience)
    
    // æå–å…¬å¸ä¿¡æ¯
    const companyRegex = /([^\n\r]*(?:å…¬å¸|é›†å›¢|ç§‘æŠ€|æœ‰é™)[^\n\r]*)/g
    const companies = experienceSection.match(companyRegex) || []
    
    // æå–èŒä½ä¿¡æ¯
    const positionRegex = /([^\n\r]*(?:å·¥ç¨‹å¸ˆ|ç»ç†|ä¸»ç®¡|æ€»ç›‘|ä¸“å‘˜)[^\n\r]*)/g
    const positions = experienceSection.match(positionRegex) || []
    
    // æå–æ—¶é—´ä¿¡æ¯
    const timeRegex = /(\d{4}[\.\-\/å¹´]\d{1,2}[\.\-\/æœˆ]?\d{0,2}[æ—¥]?)/g
    const times = experienceSection.match(timeRegex) || []
    
    return {
      companies,
      positions,
      times,
      raw: experienceSection,
      basic: basicExperience
    }
  }

  /**
   * æå–æŠ€èƒ½ä¿¡æ¯
   */
  extractSkills(text, basicSkills = []) {
    const skillsSection = this.extractSection(text, this.chineseKeywords.skills)
    
    // æŠ€æœ¯æŠ€èƒ½å…³é”®è¯
    const techSkills = [
      'JavaScript', 'Python', 'Java', 'C++', 'C#', 'PHP', 'Go', 'Rust',
      'React', 'Vue', 'Angular', 'Node.js', 'Express', 'Django', 'Spring',
      'MySQL', 'PostgreSQL', 'MongoDB', 'Redis', 'Elasticsearch',
      'Docker', 'Kubernetes', 'AWS', 'Azure', 'Git', 'Linux'
    ]
    
    const foundSkills = []
    techSkills.forEach(skill => {
      if (text.toLowerCase().includes(skill.toLowerCase())) {
        foundSkills.push(skill)
      }
    })
    
    return {
      technical: foundSkills,
      raw: skillsSection,
      basic: basicSkills
    }
  }

  /**
   * æå–é¡¹ç›®ç»éªŒ
   */
  extractProjects(text) {
    const projectSection = this.extractSection(text, this.chineseKeywords.projects)
    
    // æå–é¡¹ç›®åç§°
    const projectRegex = /é¡¹ç›®[:ï¼š]\s*([^\n\r]+)/g
    const projects = []
    let match
    
    while ((match = projectRegex.exec(projectSection)) !== null) {
      projects.push(match[1].trim())
    }
    
    return {
      projects,
      raw: projectSection
    }
  }

  /**
   * æå–æ–‡æœ¬æ®µè½
   */
  extractSection(text, keywords) {
    for (const keyword of keywords) {
      const regex = new RegExp(`${keyword}[\\s\\S]*?(?=(?:${this.chineseKeywords.personal.join('|')}|${this.chineseKeywords.education.join('|')}|${this.chineseKeywords.experience.join('|')}|${this.chineseKeywords.skills.join('|')})|$)`, 'i')
      const match = text.match(regex)
      if (match) {
        return match[0]
      }
    }
    return ''
  }

  /**
   * è®¡ç®—èŒä½åŒ¹é…åº¦
   */
  async calculateJobMatch(parsedData, targetPosition) {
    if (!targetPosition) {
      return {
        overallScore: 0,
        skillMatch: 0,
        experienceMatch: 0,
        educationMatch: 0,
        details: 'æœªæä¾›ç›®æ ‡èŒä½'
      }
    }

    // æŠ€èƒ½åŒ¹é…åº¦
    const skillMatch = this.calculateSkillMatch(parsedData.skills, targetPosition)
    
    // ç»éªŒåŒ¹é…åº¦
    const experienceMatch = this.calculateExperienceMatch(parsedData.experience, targetPosition)
    
    // æ•™è‚²èƒŒæ™¯åŒ¹é…åº¦
    const educationMatch = this.calculateEducationMatch(parsedData.education, targetPosition)
    
    // ç»¼åˆè¯„åˆ†
    const overallScore = Math.round(
      skillMatch * 0.5 + 
      experienceMatch * 0.3 + 
      educationMatch * 0.2
    )

    return {
      overallScore,
      skillMatch,
      experienceMatch,
      educationMatch,
      details: {
        strengths: this.identifyStrengths(parsedData, targetPosition),
        weaknesses: this.identifyWeaknesses(parsedData, targetPosition)
      }
    }
  }

  /**
   * è®¡ç®—æŠ€èƒ½åŒ¹é…åº¦
   */
  calculateSkillMatch(skills, targetPosition) {
    const positionSkillMap = {
      'å‰ç«¯å·¥ç¨‹å¸ˆ': ['JavaScript', 'React', 'Vue', 'CSS', 'HTML', 'TypeScript'],
      'åç«¯å·¥ç¨‹å¸ˆ': ['Java', 'Python', 'Node.js', 'MySQL', 'Redis', 'Spring'],
      'å…¨æ ˆå·¥ç¨‹å¸ˆ': ['JavaScript', 'React', 'Node.js', 'MySQL', 'Python'],
      'æ•°æ®åˆ†æå¸ˆ': ['Python', 'SQL', 'Excel', 'Tableau', 'R'],
      'äº§å“ç»ç†': ['äº§å“è®¾è®¡', 'ç”¨æˆ·ç ”ç©¶', 'æ•°æ®åˆ†æ', 'Axure', 'Figma']
    }
    
    const requiredSkills = positionSkillMap[targetPosition] || []
    if (requiredSkills.length === 0) return 50
    
    const userSkills = skills.technical || []
    const matchedSkills = requiredSkills.filter(skill => 
      userSkills.some(userSkill => 
        userSkill.toLowerCase().includes(skill.toLowerCase())
      )
    )
    
    return Math.round((matchedSkills.length / requiredSkills.length) * 100)
  }

  /**
   * è®¡ç®—ç»éªŒåŒ¹é…åº¦
   */
  calculateExperienceMatch(experience, targetPosition) {
    // ç®€åŒ–å®ç°ï¼ŒåŸºäºèŒä½å…³é”®è¯åŒ¹é…
    const experienceText = experience.raw || ''
    const positionKeywords = targetPosition.split(/[å·¥ç¨‹å¸ˆ|ç»ç†|ä¸“å‘˜|åŠ©ç†]/)
    
    let matchScore = 0
    positionKeywords.forEach(keyword => {
      if (keyword && experienceText.includes(keyword)) {
        matchScore += 20
      }
    })
    
    return Math.min(matchScore, 100)
  }

  /**
   * è®¡ç®—æ•™è‚²èƒŒæ™¯åŒ¹é…åº¦
   */
  calculateEducationMatch(education, targetPosition) {
    const degrees = education.degrees || []
    const schools = education.schools || []
    
    let score = 50 // åŸºç¡€åˆ†
    
    // å­¦ä½åŠ åˆ†
    if (degrees.some(degree => ['æœ¬ç§‘', 'å­¦å£«'].includes(degree))) score += 20
    if (degrees.some(degree => ['ç¡•å£«', 'ç ”ç©¶ç”Ÿ'].includes(degree))) score += 30
    if (degrees.some(degree => ['åšå£«'].includes(degree))) score += 40
    
    // çŸ¥åå­¦æ ¡åŠ åˆ†
    const famousSchools = ['æ¸…å', 'åŒ—å¤§', 'å¤æ—¦', 'äº¤å¤§', 'æµ™å¤§']
    if (schools.some(school => famousSchools.some(famous => school.includes(famous)))) {
      score += 20
    }
    
    return Math.min(score, 100)
  }

  /**
   * è¯†åˆ«ä¼˜åŠ¿
   */
  identifyStrengths(parsedData, targetPosition) {
    const strengths = []
    
    if (parsedData.skills.technical.length > 5) {
      strengths.push('æŠ€æœ¯æ ˆä¸°å¯Œï¼ŒæŒæ¡å¤šç§å¼€å‘æŠ€èƒ½')
    }
    
    if (parsedData.experience.companies.length > 2) {
      strengths.push('å·¥ä½œç»éªŒä¸°å¯Œï¼Œæœ‰å¤šå®¶å…¬å¸ç»å†')
    }
    
    if (parsedData.projects.projects.length > 3) {
      strengths.push('é¡¹ç›®ç»éªŒå……è¶³ï¼Œå‚ä¸è¿‡å¤šä¸ªé¡¹ç›®')
    }
    
    return strengths
  }

  /**
   * è¯†åˆ«ä¸è¶³
   */
  identifyWeaknesses(parsedData, targetPosition) {
    const weaknesses = []
    
    if (parsedData.skills.technical.length < 3) {
      weaknesses.push('æŠ€æœ¯æŠ€èƒ½ç›¸å¯¹è¾ƒå°‘ï¼Œå»ºè®®è¡¥å……ç›¸å…³æŠ€èƒ½')
    }
    
    if (parsedData.experience.companies.length === 0) {
      weaknesses.push('ç¼ºä¹å·¥ä½œç»éªŒï¼Œå»ºè®®å¢åŠ å®ä¹ æˆ–é¡¹ç›®ç»å†')
    }
    
    return weaknesses
  }

  /**
   * ç”Ÿæˆæ”¹è¿›å»ºè®®
   */
  generateImprovements(parsedData, targetPosition) {
    const improvements = []
    
    // æŠ€èƒ½æ”¹è¿›å»ºè®®
    if (parsedData.skills.technical.length < 5) {
      improvements.push({
        category: 'æŠ€èƒ½æå‡',
        suggestion: 'å»ºè®®å­¦ä¹ æ›´å¤šä¸ç›®æ ‡èŒä½ç›¸å…³çš„æŠ€æœ¯æŠ€èƒ½',
        priority: 'high'
      })
    }
    
    // ç»éªŒæ”¹è¿›å»ºè®®
    if (parsedData.experience.companies.length < 2) {
      improvements.push({
        category: 'ç»éªŒç§¯ç´¯',
        suggestion: 'å»ºè®®å¢åŠ å®ä¹ ç»å†æˆ–å‚ä¸æ›´å¤šé¡¹ç›®',
        priority: 'medium'
      })
    }
    
    // ç®€å†æ ¼å¼å»ºè®®
    improvements.push({
      category: 'ç®€å†ä¼˜åŒ–',
      suggestion: 'å»ºè®®ä½¿ç”¨æ›´æ¸…æ™°çš„æ®µè½ç»“æ„å’Œå…³é”®è¯',
      priority: 'low'
    })
    
    return improvements
  }
}

// åˆå§‹åŒ–è§£æå™¨
const resumeParser = new EnterpriseResumeParser()

// APIè·¯ç”±
app.use(express.json())

/**
 * ç®€å†è§£æAPI
 */
app.post('/api/parse-resume', 
  upload.single('resume'),
  [
    body('targetPosition').optional().isString().trim()
  ],
  async (req, res) => {
    try {
      // éªŒè¯è¯·æ±‚
      const errors = validationResult(req)
      if (!errors.isEmpty()) {
        return res.status(400).json({
          success: false,
          error: 'è¯·æ±‚å‚æ•°é”™è¯¯',
          details: errors.array()
        })
      }

      if (!req.file) {
        return res.status(400).json({
          success: false,
          error: 'è¯·ä¸Šä¼ ç®€å†æ–‡ä»¶'
        })
      }

      const { targetPosition = '' } = req.body
      
      // è§£æç®€å†
      const result = await resumeParser.parseResume(
        req.file.path,
        req.file.originalname,
        targetPosition
      )
      
      res.json(result)
      
    } catch (error) {
      console.error('ç®€å†è§£æAPIé”™è¯¯:', error)
      res.status(500).json({
        success: false,
        error: 'ç®€å†è§£æå¤±è´¥',
        message: error.message
      })
    }
  }
)

/**
 * å¥åº·æ£€æŸ¥API
 */
app.get('/api/health', (req, res) => {
  res.json({
    status: 'ok',
    timestamp: new Date().toISOString(),
    service: 'resume-parser'
  })
})

// é”™è¯¯å¤„ç†ä¸­é—´ä»¶
app.use((error, req, res, next) => {
  console.error('æœåŠ¡å™¨é”™è¯¯:', error)
  
  if (error instanceof multer.MulterError) {
    if (error.code === 'LIMIT_FILE_SIZE') {
      return res.status(400).json({
        success: false,
        error: 'æ–‡ä»¶å¤§å°è¶…è¿‡é™åˆ¶ï¼ˆæœ€å¤§10MBï¼‰'
      })
    }
  }
  
  res.status(500).json({
    success: false,
    error: 'æœåŠ¡å™¨å†…éƒ¨é”™è¯¯'
  })
})

// å¯åŠ¨æœåŠ¡å™¨
async function startServer() {
  try {
    await initializeNLP()
    
    app.listen(PORT, () => {
      console.log(`ğŸš€ ä¼ä¸šçº§ç®€å†è§£ææœåŠ¡å¯åŠ¨æˆåŠŸ`)
      console.log(`ğŸ“¡ æœåŠ¡åœ°å€: http://localhost:${PORT}`)
      console.log(`ğŸ“‹ APIæ–‡æ¡£: http://localhost:${PORT}/api/health`)
    })
  } catch (error) {
    console.error('æœåŠ¡å¯åŠ¨å¤±è´¥:', error)
    process.exit(1)
  }
}

startServer()